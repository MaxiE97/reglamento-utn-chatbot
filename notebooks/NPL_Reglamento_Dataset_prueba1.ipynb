{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbbdea9b-bcaa-425b-bd78-9e9be56d00fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Ollama -q\n",
    "!pip install langchain -q\n",
    "!pip install langchain_community -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d19a93f-76b7-47fd-96f8-c6b9c723042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from langchain_community.llms import Ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c74ee1c9-6a73-4d13-a453-7d851dec2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model=\"llama3\", temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0938e2a2-030a-47c1-b285-b9fe12b2723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptInicial = f\"\"\"\n",
    "Dado el siguiente artículo, genera preguntas y respuestas relacionadas con el contenido del texto.\n",
    "\n",
    "El formato debe ser:\n",
    "\n",
    "Pregunta: <pregunta>\n",
    "Respuesta: <respuesta>\n",
    "Pregunta: <pregunta>\n",
    "Respuesta: <respuesta>\n",
    "... (y así sucesivamente)\n",
    "\n",
    "La salida solo debe contener este formato, ni saludos, ni aclaraciones, solamente lo que se indica.\n",
    "\n",
    "Artículo:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8467d793-563a-4797-8254-132d20020484",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptInicial2 = f\"\"\"\n",
    "Given the following article, generate deep questions and answers related to the content of the text. The questions should explore the details and nuances of the article, without referencing any other question or the article's numbering. The format should be:\n",
    "\n",
    "Pregunta: <pregunta>\n",
    "Respuesta: <respuesta>\n",
    "Pregunta: <pregunta>\n",
    "Respuesta: <respuesta>\n",
    "... (and so on)\n",
    "\n",
    "The output should only contain this format, no greetings, no explanations, only what is indicated. What you generate must be in Spanish.\n",
    "\n",
    "\n",
    "This is the article:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "888bfe66-9885-4d1d-96b1-534a91b84b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "articulo_ejemplo = f\"\"\"\n",
    "Las convocatorias para la designación por Concurso de Profesores Ordinarios titulares, asociados y adjuntos para las diferentes cátedras, áreas, núcleos, asignaturas que integran los núcleos, disciplinas, laboratorio de las Facultades que integran esta Universidad se regirán por las disposiciones del presente Reglamento y las que en consecuencia dicten las Unidades Académicas, que deberán ser aprobadas por el Consejo Superior.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "325c8b42-8fd2-49f2-ae62-bc7857718287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qa(article, prompt):\n",
    "    formatted_prompt = f\" {prompt} {article}\"\n",
    "    response = ollama.chat(model = 'llama3',\n",
    "                           messages = [{'role':'user', 'content': formatted_prompt}],\n",
    "                           options = {'temperature':0})\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79fdac9c-71aa-4438-8b51-94bc44661468",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplo = generate_qa(articulo_ejemplo, promptInicial2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5221e7e-f5fd-4f61-a259-639f05ed1295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¿Qué tipo de convocatorias se realizarán para la designación de profesores?\n",
      "Respuesta: Convocatorias para la designación por Concurso de Profesores Ordinarios titulares, asociados y adjuntos.\n",
      "\n",
      "Pregunta: ¿Qué áreas o disciplinas serán objeto de estas convocatorias?\n",
      "Respuesta: Las diferentes cátedras, áreas, núcleos, asignaturas que integran los núcleos, disciplinas y laboratorios de las Facultades que integran esta Universidad.\n",
      "\n",
      "Pregunta: ¿Quién será responsable de dictar disposiciones para la designación de profesores?\n",
      "Respuesta: Las Unidades Académicas, que deberán ser aprobadas por el Consejo Superior.\n",
      "\n",
      "Pregunta: ¿Qué papel jugará el Consejo Superior en este proceso?\n",
      "Respuesta: Aprobar las disposiciones que dicten las Unidades Académicas.\n"
     ]
    }
   ],
   "source": [
    "print(ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ddd0511-0c60-427b-b6d9-7dc9d2db3bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Obsevaciones:\n",
    "\n",
    " ## Parece que los prompts laburan mejor en inglés\n",
    "\n",
    " ## Si le quito el documento/articulo/capitulo parece que las pregunta y respuestas no hacen TANTA referencia al documento/convocatoria/capitulo\n",
    "\n",
    " ## Parece que se puede toquear el prompt hasta que dé mejores resultado, de todas formas con un modelo avanzado andaría mejor? \n",
    "\n",
    " ## De todas formas parece que el fine tuning no influye muco en que un modelo adquiera nuevo conocimiento, sino en poder modificar el comportamiento \n",
    "    #en la respuesta de los modelos, para lo otro sería mas útil usar un RAG\n",
    "    #Dicho esto, ¿Vale la pena que el data set tenga preguntas totalmente exactas y profundas si parece que no puede adquirir conocimiento?\n",
    "\n",
    " ## Lo que si se podría hacer con el fine tuning capaz es darle la capacidad para que tenga un formato de respuesta que responda con el\n",
    "    # DOCUMENTO - ARTICULO - CAPITULO; Capaz también puede adquirir mejor entendimiento de las palabras técnicas que tiene el documento;  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05426e5-6bd1-4133-b8e8-a642447286a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
